{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# PCA and senate voting data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In this problem, we are given the $m \\times n$ data matrix $X$ with entries in $\\{-1,0,1\\}$, where each row corresponds to a senator and each column to a bill. We first import this data, print some relevant values, and normalize it as necessary to ready it for further computation.\n",
    "\n",
    "To run this code, you'll need a number of standard Python libraries, all of which are installable via $\\texttt{pip}$ or $\\texttt{conda}$. We highly recommend using a [virtual environment](https://realpython.com/python-virtual-environments-a-primer/), for this class and in general.\n",
    "\n",
    "Lastly, ensure that all data files (`senator_pca_data_matrix.csv` and `senator_pca_politician_labels.txt`) are located in the same folder as the notebook.\n",
    "\n",
    "### Places you will need to modify this code are enclosed in a $\\texttt{#TODO}$ block. You should not need to modify code outside these blocks to complete the problems. Questions that you are expected to answer in text are marked in <font color='red'>red</font>. For solution files, solutions will be presented in <font color='blue'>blue</font>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# import the necessary packages for data manipulation, computation and PCA \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from numpy import linalg as LA\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape:  (100, 542)\n"
     ]
    }
   ],
   "source": [
    "# import the data matrix\n",
    "senator_df =  pd.read_csv('senator_pca_data_matrix.csv')\n",
    "affiliation_file = open('senator_pca_politician_labels.txt', 'r')\n",
    "affiliations = [line.split('\\n')[0].split(' ')[1] for line in affiliation_file.readlines()]\n",
    "X = np.array(senator_df.values[:, 3:].T, dtype='float64') # transpose to get senators as rows\n",
    "print('X.shape: ', X.shape)\n",
    "n = X.shape[0] # number of senators\n",
    "d = X.shape[1] # number of bills"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We observe that the number of rows, $n$, is the number of senators and is equal to 100. The number of columns, $d$, is the number of bills and is equal to 542. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(542,)\n",
      "[ 1.  1.  1. -1. -1.  1.  1.  1.  1. -1.  1. -1. -1.  1.  1. -1.  1.  1.\n",
      "  1.  1.  1. -1.  1.  1.  1. -1.  1. -1.  1.  1.  1.  1.  1. -1.  1. -1.\n",
      " -1. -1. -1.  1.  1. -1. -1. -1. -1.  1.  1.  1. -1.  1.  1. -1.  1.  1.\n",
      " -1.  1.  1.  1.  1. -1.  1. -1. -1. -1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1. -1.  0. -1.  1.  1.  1. -1. -1.  1.  1. -1. -1.  1.  1.  1. -1.\n",
      "  1. -1.  1. -1.  1.  1. -1. -1. -1.  1.  1.  1. -1. -1. -1. -1. -1. -1.\n",
      "  1. -1.  1.  1. -1. -1. -1.  1. -1.  1. -1.  1.  0.  0.  1.  1. -1.  1.\n",
      "  1. -1.  1.  1. -1.  1. -1. -1.  1.  1.  1.  1.  0. -1. -1.  1.  1. -1.\n",
      "  1.  1.  1.  1.  1.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.\n",
      " -1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  0.  1. -1. -1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1. -1.\n",
      "  1.  1.  0.  1.  0. -1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1. -1.\n",
      "  1.  1.  1.  1.  1.  1. -1. -1. -1.  1.  1. -1.  1. -1. -1.  1.  1.  1.\n",
      " -1.  1.  1.  1. -1.  1. -1.  1. -1. -1.  1. -1. -1.  1.  1.  1. -1.  1.\n",
      "  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1. -1.\n",
      "  1. -1.  1. -1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1. -1.  1. -1.\n",
      "  1.  1.  1.  1.  1.  1. -1.  1. -1. -1. -1. -1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1. -1. -1.  1. -1.  1.  1.  1.\n",
      "  1.  1. -1.  1. -1.  1. -1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  0.  1. -1.  1.  1.  1.  1.  1. -1. -1. -1.  1.  1.  0.  1.  1.  1.\n",
      "  1.  1.  1.  1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  1.  1. -1. -1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1. -1.  1.  1.  1.  1. -1. -1.\n",
      "  1.  1.  1.  1. -1. -1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.\n",
      " -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1. -1. -1. -1.  1.  1.  1.  1. -1. -1.  1.  1. -1.  1.  1.  1.  1.\n",
      "  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "# print an example row of the data matrix\n",
    "typical_row = X[0]\n",
    "print(typical_row.shape)\n",
    "print(typical_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "A row of $X$ consists of 542 entries -1 (senator voted against), 1 (senator voted for), or 0 (senator abstained), one for each bill. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,)\n",
      "[ 1.  1.  1.  1.  1.  1.  1. -1.  1. -1.  1. -1.  1. -1. -1. -1.  1.  1.\n",
      " -1.  1.  1. -1.  1. -1.  1.  1.  1. -1. -1.  1.  1.  1. -1.  1.  1.  1.\n",
      " -1. -1. -1. -1.  1. -1. -1.  1.  1. -1. -1. -1. -1. -1.  1.  1. -1. -1.\n",
      "  1.  1. -1. -1. -1. -1. -1.  1.  1.  1.  1.  1. -1. -1. -1.  1. -1. -1.\n",
      "  1. -1. -1.  1.  1.  1. -1. -1. -1.  1.  1. -1.  1. -1.  1.  1.  1. -1.\n",
      " -1. -1. -1. -1.  1.  1.  1. -1. -1. -1.]\n"
     ]
    }
   ],
   "source": [
    "# print an example column of the data matrix\n",
    "typical_column = X[:,0]\n",
    "print(typical_column.shape)\n",
    "print(typical_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "A column of $X$ consists of 100 entries in \\{-1, 0, 1\\}, one for each senator that voted on the bill."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# compute the mean vote on each bill\n",
    "X_mean = np.mean(X, axis = 0)\n",
    "plt.plot(X_mean)\n",
    "plt.title('means of each column of X')\n",
    "plt.xlabel('column/bill')\n",
    "plt.ylabel('mean vote')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We observe that the mean of the columns is not zero, so we center the data by subtracting the mean of each bill's vote from its respective column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# center the data matrix\n",
    "X_original = X.copy() # save a copy for part (d) and (e)\n",
    "X = X - np.mean(X, axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## a) Maximizing $\\sigma^{2}(f(X,\\vec{a}))$\n",
    "\n",
    "In this problem, you are asked to find a unit-norm vector $\\vec{a} \\in \\mathbb{R}^{d}$ maximizing the empirical variance $\\sigma^{2}(f(X,\\vec{a}))$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We first provide a function to calculate the scores, $f(X,\\vec{a})$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# define score function\n",
    "def f(X, a):\n",
    "    return X @ a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Before we calculate the $\\vec{a}$ that maximizes variance, let's observe what the scalar projections on a random direction $\\vec{a}$ look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# generate a random direction and normalize the vector\n",
    "a_rand = np.random.rand(d)\n",
    "a_rand = a_rand/np.linalg.norm(a_rand)\n",
    "\n",
    "# compute associated scores along a_rand\n",
    "scores_rand = f(X, a_rand)\n",
    "\n",
    "# visualize the scores along a_rand, coloring them by party affiliation\n",
    "plt.scatter(scores_rand, np.zeros_like(scores_rand), c=affiliations)\n",
    "plt.title('projections along random direction a_rand')\n",
    "plt.xlabel('$\\\\langle x_i, a\\\\rangle$')\n",
    "cur_axes = plt.gca()\n",
    "cur_axes.axes.get_yaxis().set_visible(False)\n",
    "plt.show()\n",
    "\n",
    "print('variance along random direction a_rand: ', scores_rand.var())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Note here that projecting along the random vector $\\texttt{a_rand}$ does not explain much variance at all — data points are clustered together and intermixed across parties. It is clear that this direction does not give us any information about the senators' affiliations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "### TODO: Calculate a_1, the first principal component of X.\n",
    "# Hint: The PCA package imported from sklearn.decomposition will be useful here, \n",
    "# in particular the function pca.fit(). What should the dimensions of a_1 be?\n",
    "\n",
    "\n",
    "### end TODO\n",
    "################################################################################\n",
    "\n",
    "a_1 = a_1/np.linalg.norm(a_1)\n",
    "# compute and visualize the scores along a_1\n",
    "scores_a_1 = f(X, a_1)\n",
    "\n",
    "plt.scatter(scores_a_1, np.zeros_like(scores_a_1), c=affiliations)\n",
    "plt.title('projections along first principal component a_1')\n",
    "plt.xlabel('$\\\\langle x_i, a \\\\rangle$')\n",
    "cur_axes = plt.gca()\n",
    "cur_axes.axes.get_yaxis().set_visible(False)\n",
    "plt.show()\n",
    "\n",
    "print('variance along first principal component: ', scores_a_1.var())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "If you computed $\\texttt{a_1}$ correctly, you should observe that the variance is much higher than the $\\texttt{a_rand}$ projection, and that blue and red dots are now spread in two clusters. This makes sense: the first principal component is the direction along which data varies most, and that is often along party lines. You just found a mathematical model for partisanship!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## b) Comparison to party averages\n",
    "\n",
    "We observed above that the direction of maximum variance appears to be determined by party alignment; we now want to quantify how true that is by computing variance along vectors that describe the average position of each party. Specifically, we will compute variance along the following two vectors:\n",
    "\n",
    "- $\\texttt{a_mean_red}$: unit vector along the mean of rows of $\\texttt{X}$ corresponding to ‘Red’ senators\n",
    "- $\\texttt{a_mean_blue}$: unit vector along the mean of rows of $\\texttt{X}$ corresponding to ‘Blue’ senators\n",
    "\n",
    "#### Fill in the code as indicated below to calculate these values and compute their relationships to $\\texttt{a_1}$ and each other, then answer the interpretation question that follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "### TODO: Calculate mu_red, the array of dimension (542, ) whose values \n",
    "### are the mean across rows of X corresponding to 'Red' senators only.\n",
    "# Hint: Print out the 'affiliations' variable and observe its contents.\n",
    "# print(len(affiliations))\n",
    "# print(affiliations)\n",
    "\n",
    "\n",
    "### end TODO\n",
    "################################################################################\n",
    "\n",
    "# normalize the vector to generate unit a_mean_red\n",
    "a_mean_red = mu_red/np.linalg.norm(mu_red)\n",
    "\n",
    "# compute and visualize the scores along a_mean_red\n",
    "scores_mean_red = f(X, a_mean_red)\n",
    "\n",
    "plt.scatter(scores_mean_red, np.zeros_like(scores_mean_red), c=affiliations)\n",
    "plt.title('projections along mean voting vector of red senators')\n",
    "plt.xlabel('$\\\\langle x_i, a \\\\rangle$')\n",
    "cur_axes = plt.gca()\n",
    "cur_axes.axes.get_yaxis().set_visible(False)\n",
    "plt.show()\n",
    "\n",
    "print('variance along mean voting vector of red senators: ', scores_mean_red.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "### TODO: Calculate mu_blue, the array of dimension (542, ) whose values \n",
    "### are the mean across rows of X corresponding to 'RBlue' senators only.\n",
    "# Hint: Print out the 'affiliations' variable and observe its contents.\n",
    "# print(len(affiliations))\n",
    "# print(affiliations)\n",
    "\n",
    "\n",
    "### end TODO\n",
    "################################################################################\n",
    "\n",
    "# normalize the vector to generate unit a_mean_blue\n",
    "a_mean_blue = mu_blue/np.linalg.norm(mu_blue)\n",
    "\n",
    "# compute and visualize the scores along a_mean_blue\n",
    "scores_mean_blue = f(X, a_mean_blue)\n",
    "\n",
    "plt.scatter(scores_mean_blue, np.zeros_like(scores_mean_blue), c=affiliations)\n",
    "plt.title('projections along mean voting vector of blue senators')\n",
    "plt.xlabel('$\\\\langle x_i, a \\\\rangle$')\n",
    "cur_axes = plt.gca()\n",
    "cur_axes.axes.get_yaxis().set_visible(False)\n",
    "plt.show()\n",
    "\n",
    "print('variance along mean voting vector of blue senators: ', scores_mean_blue.var())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# compute dot product of and angle between a_mean_red and a_mean_blue:\n",
    "dot_product_blue_red = a_mean_blue.T @ a_mean_red\n",
    "angle_blue_red = np.arccos(dot_product_blue_red) * 180/np.pi\n",
    "\n",
    "print('dot product of a_mean_blue and a_mean_red: ', dot_product_blue_red)\n",
    "print('angle between a_mean_blue and a_mean_red (degrees): ', angle_blue_red)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### <font color='red'>TODO: Interpretation</font>\n",
    "#### <font color='red'> Comment on the relationships between $\\texttt{a_mean_red}$ and $\\texttt{a_mean_blue}$ above based on their dot products and relative angles.\n",
    "</font>\n",
    "\n",
    "#### <font color='blue'> TODO\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will see how aligned the mean voting vectors are with the first principal component of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# check angle between mean voting vector of red senators and the first principal component as well as that of blue senators and the first principal component\n",
    "dot_product_red_a1 = a_mean_red.T @ a_1\n",
    "angle_red_a1 = np.arccos(dot_product_red_a1) * 180/np.pi\n",
    "\n",
    "print('dot product of a_mean_red and a_1: ', dot_product_red_a1)\n",
    "print('angle between a_mean_red and a_1 (degrees): ', angle_red_a1)\n",
    "\n",
    "dot_product_blue_a1 = a_mean_blue.T @ a_1\n",
    "angle_blue_a1 = np.arccos(dot_product_blue_a1) * 180/np.pi\n",
    "\n",
    "print('dot product of a_mean_blue and a_1: ', dot_product_blue_a1)\n",
    "print('angle between a_mean_blue and a_1 (degrees): ', angle_blue_a1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### <font color='red'>TODO: Interpretation</font>\n",
    "#### <font color='red'> Comment on the relationships between Red and Blue senators to partisanship based on the two products of $\\texttt{a_mean_blue}$ and $\\texttt{a_mean_red}$ with $\\texttt{a_1}$, the top principal component of the covariance, i.e., the maximum variance direction.\n",
    "</font>\n",
    "\n",
    "#### <font color='blue'> TODO\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## c) Computing total variance\n",
    "\n",
    "We now wish to observe the variance of the data along the first two principal component axes.\n",
    "\n",
    "#### Fill in the code below to calculate the total variance of the data along the first two principal components $\\texttt{a_1}$ and $\\texttt{a_2}$ and to plot the data on the corresponding axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "### TODO: Calculate the Sigma matrix (defined in LaTeX problem) and the total variance across a_1 and a_2.\n",
    "# Hint: The latter value is equal to the sum of the two largest eigenvalues of Sigma. You can use either the PCA library or the numpy.linalg library that were already imported at the start of this notebook.\n",
    "\n",
    "\n",
    "### end TODO\n",
    "################################################################################\n",
    "print(Sigma)\n",
    "print('total variance explained by first two principal components: ', total_variance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Next, we calculate and plot the projection onto the plane spanned by the first two principal components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# calculate projected data matrix and observe its shape\n",
    "pca = PCA(n_components=2)\n",
    "projected = pca.fit_transform(X)\n",
    "print(projected.shape)\n",
    "\n",
    "# plot projected data matrix\n",
    "plt.scatter(projected[:, 0], projected[:, 1], c=affiliations)\n",
    "plt.xlabel('a_1')\n",
    "plt.ylabel('a_2')\n",
    "plt.title('projection on plane spanned by first two principal components')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## d) Finding bills that are the most/least contentious\n",
    "\n",
    "We now wish to observe which bills are the most and least contentious — i.e., those for which most senators voted unanimously, and those for which support was most varied. We consider one possible way of quantifying this relationship mathematically.\n",
    "\n",
    "We can compute the variance of each column of $X$ — each of which corresponds to a particular bill — and use this variance as a measure of \"contentiousness\" (i.e., the more contentious a bill, the higher its variance in terms of senator vote count). Note that the variance of a particular bill in column $j$ can be viewed as the variance of scores along $\\vec{e}_j$, where $\\vec{e}_j$ is a basis vector whose $j^\\textrm{th}$ entry is 1 and all others 0.\n",
    "\n",
    "#### Fill in the code below to calculate the variance of $X$, extract the most and least contentious bills, and plot their vote counts, commenting on your results where indicated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# calculate the variance of each column\n",
    "list_variances = X.var(axis=0)\n",
    "bills = senator_df['bill_type bill_name bill_ID'].values\n",
    "\n",
    "################################################################################\n",
    "### TODO: Compute sorted_idx_variances, an np.array of shape (542,) containing\n",
    "### integer entries that are the indices of variance scores in list_variances in\n",
    "### decreasing order of variance. For example, if list_variances = [1, 3, 2, 4], \n",
    "### then sorted_idx_variances = np.array([3,1,2,0]).\n",
    "# Hint: Use np.argsort().\n",
    "\n",
    "\n",
    "### end TODO\n",
    "################################################################################\n",
    "\n",
    "print(sorted_idx_variances.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Using this sorted index, we can now plot the vote counts for the top 5 highest and lowest variance bills."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# retrieve the bills with the 5 highest and lowest variances\n",
    "top_5 = [bills[sorted_idx_variances[i]] for i in range(5)]\n",
    "bot_5 = [bills[sorted_idx_variances[-1-i]] for i in range(5)]\n",
    "\n",
    "# set up figure with all desired subplots\n",
    "fig, axes = plt.subplots(5,2, figsize=(15,15))\n",
    "\n",
    "# plot highest variance bills\n",
    "for i in range(5): \n",
    "    idx = sorted_idx_variances[i]\n",
    "    \n",
    "    # retrieve vote counts from original uncentered data matrix\n",
    "    X_red_c = X_original[np.array(affiliations) == 'Red',idx]\n",
    "    X_blue_c = X_original[np.array(affiliations) == 'Blue',idx]\n",
    "    X_yellow_c = X_original[np.array(affiliations) == 'Yellow',idx]\n",
    "    \n",
    "    axes[i,0].hist([X_red_c, X_blue_c, X_yellow_c], color = ['red', 'blue', 'yellow'])\n",
    "    axes[i,0].set_title(bills[idx])\n",
    "\n",
    "# plot lowest variance bills\n",
    "for i in range(1,6): \n",
    "    idx2 = sorted_idx_variances[-i]\n",
    "    \n",
    "    # retrieve vote counts from original uncentered data matrix\n",
    "    X_red_c2 = X_original[np.array(affiliations) == 'Red',idx2]\n",
    "    X_blue_c2 = X_original[np.array(affiliations) == 'Blue',idx2]\n",
    "    X_yellow_c2 = X_original[np.array(affiliations) == 'Yellow',idx2]\n",
    "    \n",
    "    axes[i-1,1].hist([X_red_c2, X_blue_c2, X_yellow_c2], color = ['red', 'blue', 'yellow'])\n",
    "    axes[i-1,1].set_title(bills[idx2])\n",
    "\n",
    "plt.subplots_adjust(hspace=0.5, wspace = 1)    \n",
    "fig.suptitle('Most Variance -- Least Variance', fontsize=16)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### <font color='red'>TODO: Interpretation</font>\n",
    "#### <font color='red'> Comment on the voting trends you observe in the plots above. In general, if a vote is contentious, what do you expect the plots to look like? What about if a vote is uncontentious?\n",
    "</font>\n",
    "\n",
    "#### <font color='blue'> TODO\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# e) Infer political affiliation using top two PCA directions\n",
    "We now consider a strategy to infer the political affiliation of two senators based on how they voted for the bills and considering the projection of their votes onto the two principal components.\n",
    "\n",
    "In this part, we will compute the top two PCA directions for our given data after removing two specific senators. Then we will plot all the senators in 2D based on their projections on the top two directions as in part c). The two senators whose affiliation needs to be inferred are marked in green and gray. Can you infer the political affiliation (Red or Blue) of the green and gray senator by looking at the points in this 2D plane?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train=np.delete(X,[0,1],0)\n",
    "affiliations_train=affiliations[:]\n",
    "affiliations_train[0]='Green'\n",
    "affiliations_train[1]='Gray'\n",
    "\n",
    "# calculate projected data matrix and observe its shape\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(X_train)\n",
    "projected = pca.transform(X)\n",
    "print(projected.shape)\n",
    "\n",
    "# plot projected data matrix\n",
    "plt.scatter(projected[:, 0], projected[:, 1], c=affiliations_train)\n",
    "plt.xlabel('a_1')\n",
    "plt.ylabel('a_2')\n",
    "plt.title('projection on plane spanned by first two principal components')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### <font color='red'>TODO: Interpretation</font>\n",
    "#### <font color='red'> Based on the plot above, what is the likely affiliation of the Green senator? What is the likely affiliation of the Grey senator?\n",
    "</font>\n",
    "\n",
    "#### <font color='blue'> TODO\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## f) Finding extreme senators\n",
    "\n",
    "Lastly, let us return to our initial definition of $f(X,\\vec{a})$, which assigns each senator a score. We will now use this value computed along the first principal component $\\vec{a}$ to assign the following classifications to our senators:\n",
    "\n",
    "- Senators with the top 10 most positive scores and top 10 most negative scores are classified as *most extreme*.\n",
    "- Senators with the 20 scores closest to 0 are classified as *least extreme*.\n",
    "\n",
    "In the final subproblem, we observe these scores and how they relate to party affiliation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We first compute the most extreme senators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# extract senator names\n",
    "senators = senator_df.columns.values[3:]\n",
    "\n",
    "# compute and sort senators scores and corresponding affiliations\n",
    "senator_scores = f(X,a_1)\n",
    "complete_sort_indices = np.argsort(senator_scores)\n",
    "sort_indices = np.hstack([complete_sort_indices[:10], complete_sort_indices[-11:-1]])\n",
    "senators_sorted = senators[sort_indices]\n",
    "senator_scores_sorted = senator_scores[sort_indices]\n",
    "affiliations = np.array(affiliations)\n",
    "affiliations_sorted = affiliations[sort_indices]\n",
    "\n",
    "plt.barh(y = senators_sorted, width = senator_scores_sorted, color = affiliations_sorted)\n",
    "plt.title('scores of the most extreme \\'Red\\' and \\'Blue\\' senators')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "And the least extreme senators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# compute and sort senators scores and corresponding affiliations\n",
    "senator_scores = f(X,a_1)\n",
    "complete_sort_indices = np.argsort(np.abs(senator_scores))[:20]\n",
    "senator_scores_le= senator_scores[complete_sort_indices]\n",
    "senators_le = senators[complete_sort_indices]\n",
    "affiliations = np.array(affiliations)\n",
    "affiliations_le = affiliations[complete_sort_indices]\n",
    "sort_indices = np.argsort(senator_scores_le)\n",
    "senators_sorted = senators_le[sort_indices]\n",
    "senator_scores_sorted = senator_scores_le[sort_indices]\n",
    "affiliations_sorted = affiliations_le[sort_indices]\n",
    "\n",
    "plt.barh(y = senators_sorted, width = senator_scores_sorted, color = affiliations_sorted)\n",
    "plt.title('scores of the least extreme \\'Red\\' and \\'Blue\\' senators')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### <font color='red'>TODO: Interpretation</font>\n",
    "#### <font color='red'> Comment on the sign of senators' scores and what they say about party affiliation for both the most and least extreme senators.\n",
    "</font>\n",
    "\n",
    "#### <font color='blue'> TODO\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
